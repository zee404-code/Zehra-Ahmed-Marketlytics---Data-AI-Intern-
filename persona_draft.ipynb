{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Function to fetch LinkedIn profile data\n",
        "def get_profile_data(url):\n",
        "    # Send a GET request to the LinkedIn profile URL\n",
        "    response = requests.get(url)\n",
        "    # Parse the HTML content\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    # Extract the summary section from the HTML content\n",
        "    summary = soup.find('div', {'class': 'pv-top-card-section__summary'}).get_text()\n",
        "    # Extract the experience section from the HTML content\n",
        "    experience = soup.find('section', {'class': 'pv-profile-section__section experience-section ember-view'}).get_text()\n",
        "    # Extract the education section from the HTML content\n",
        "    education = soup.find('section', {'class': 'pv-profile-section__section education-section ember-view'}).get_text()\n",
        "    # Combine the summary, experience, and education sections into a single string\n",
        "    profile_data = summary + experience + education\n",
        "    return profile_data\n",
        "\n",
        "# Function to train the classifier\n",
        "def train_classifier(profile_data, labels):\n",
        "    # Use a TfidfVectorizer to convert the profile data into numerical features\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    # Use a Naive Bayes classifier to train the model\n",
        "    classifier = MultinomialNB()\n",
        "    # Create a pipeline to combine the vectorizer and classifier\n",
        "    pipeline = Pipeline([('vectorizer', vectorizer), ('classifier', classifier)])\n",
        "    # Fit the pipeline to the training data\n",
        "    pipeline.fit(profile_data, labels)\n",
        "    return pipeline\n",
        "\n",
        "# Function to predict the personality of a LinkedIn profile\n",
        "def predict_personality(pipeline, url):\n",
        "    # Get the profile data\n",
        "    profile_data = get_profile_data(url)\n",
        "    # Use the pipeline to make a prediction\n",
        "    prediction = pipeline.predict([profile_data])\n",
        "    return prediction\n",
        "\n",
        "# Example usage:\n",
        "# Training data\n",
        "profile_urls = [\n",
        "    'https://www.linkedin.com/in/alice',\n",
        "    'https://www.linkedin.com/in/bob',\n",
        "    'https://www.linkedin.com/in/charlie',\n",
        "    'https://www.linkedin.com/in/dave'\n",
        "]\n",
        "labels = ['introvert', 'extrovert', 'introvert', 'extrovert']\n",
        "# Train the classifier\n",
        "pipeline = train_classifier([get_profile_data(url) for url in profile_urls], labels)\n",
        "\n",
        "# Test data\n",
        "test_url = 'https://www.linkedin.com/in/eve'\n",
        "\n",
        "# Predict the personality\n",
        "prediction = predict_personality(pipeline, test_url)\n",
        "print(prediction)\n"
      ],
      "metadata": {
        "id": "_0xkyNC26_k5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efQAMklQ61VG"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Function to fetch LinkedIn profile data\n",
        "def get_profile_data(url):\n",
        "    # Send a GET request to the LinkedIn profile URL\n",
        "    response = requests.get(url)\n",
        "    # Parse the HTML content\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    # Extract the summary section from the HTML content\n",
        "    summary = soup.find('div', {'class': 'pv-top-card-section__summary'}).get_text()\n",
        "    # Extract the experience section from the HTML content\n",
        "    experience = soup.find('section', {'class': 'pv-profile-section__section experience-section ember-view'}).get_text()\n",
        "    # Extract the education section from the HTML content\n",
        "    education = soup.find('section', {'class': 'pv-profile-section__section education-section ember-view'}).get_text()\n",
        "    # Extract the Job titles\n",
        "    job_titles = soup.find_all('h3', {'class': 't-16 t-black t-normal'})\n",
        "    job_titles = [title.get_text() for title in job_titles]\n",
        "    # Extract the number of connections\n",
        "    connections = soup.find('a', {'data-link-to': 'about:connections'}).get_text()\n",
        "    connections = int(connections.split(' ')[0])\n",
        "    # Extract the number of Recommendations\n",
        "    recommendations = soup.find('a', {'data-link-to': 'about:recommendations'}).get_text()\n",
        "    recommendations = int(recommendations.split(' ')[0])\n",
        "    # Extract the number of Posts and Shares made by the user\n",
        "    posts = soup.find_all('span', {'class': 'visually-hidden'})\n",
        "    num_posts = 0\n",
        "    num_shares = 0\n",
        "    for post in posts:\n",
        "        if 'post' in post.get_text():\n",
        "            num_posts += int(post.get_text().split(' ')[0])\n",
        "        elif 'share' in post.get_text():\n",
        "            num_shares += int(post.get_text().split(' ')[0])\n",
        "    # Create a dictionary of the additional data\n",
        "    additional_data = {\n",
        "        'job_titles': job_titles,\n",
        "        'connections': connections,\n",
        "        'recommendations': recommendations,\n",
        "        'num_posts': num_posts,\n",
        "        'num_shares': num_shares\n",
        "    }\n",
        "    # Combine the summary, experience, and education sections into a single string\n",
        "    profile_data = summary + experience + education\n",
        "    return profile_data, additional_data\n",
        "\n",
        "# Function to train the classifier\n",
        "def train_classifier(profile_data, additional_data, labels):\n",
        "    # Combine the profile data and additional data into a single feature vector\n",
        "    features = []\n",
        "    for i in range(len(profile_data)):\n",
        "        features.append(profile_\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Function to fetch LinkedIn profile data\n",
        "def get_profile_data(url):\n",
        "    # Send a GET request to the LinkedIn profile URL\n",
        "    response = requests.get(url)\n",
        "    # Parse the HTML content\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    # Extract the summary section from the HTML content\n",
        "    summary = soup.find('div', {'class': 'pv-top-card-section__summary'}).get_text()\n",
        "    # Extract the experience section from the HTML content\n",
        "    experience = soup.find('section', {'class': 'pv-profile-section__section experience-section ember-view'}).get_text()\n",
        "    # Extract the education section from the HTML content\n",
        "    education = soup.find('section', {'class': 'pv-profile-section__section education-section ember-view'}).get_text()\n",
        "    # Extract the Job titles\n",
        "    job_titles = soup.find_all('h3', {'class': 't-16 t-black t-normal'})\n",
        "    job_titles = [title.get_text() for title in job_titles]\n",
        "    # Extract the number of connections\n",
        "    connections = soup.find('a', {'data-link-to': 'about:connections'}).get_text()\n",
        "    connections = int(connections.split(' ')[0])\n",
        "    # Extract the number of Recommendations\n",
        "    recommendations = soup.find('a', {'data-link-to': 'about:recommendations'}).get_text()\n",
        "    recommendations = int(recommendations.split(' ')[0])\n",
        "    # Extract the number of Posts and Shares made by the user\n",
        "    posts = soup.find_all('span', {'class': 'visually-hidden'})\n",
        "    num_posts = 0\n",
        "    num_shares = 0\n",
        "    for post in posts:\n",
        "        if 'post' in post.get_text():\n",
        "            num_posts += int(post.get_text().split(' ')[0])\n",
        "        elif 'share' in post.get_text():\n",
        "            num_shares += int(post.get_text().split(' ')[0])\n",
        "    # Create a dictionary of the additional data\n",
        "    additional_data = {\n",
        "        'job_titles': job_titles,\n",
        "        'connections': connections,\n",
        "        'recommendations': recommendations,\n",
        "        'num_posts': num_posts,\n",
        "        'num_shares': num_shares\n",
        "    }\n",
        "    # Combine the summary, experience, and education sections into a single string\n",
        "    profile_data = summary + experience + education\n",
        "    return profile\n"
      ],
      "metadata": {
        "id": "9E_sQHJY7BmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the pipeline\n",
        "text_transformer = TfidfVectorizer()\n",
        "numerical_transformer = StandardScaler()\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('text', text_transformer, 'profile_data'),\n",
        "        ('num', numerical_transformer, ['connections', 'recommendations', 'num_posts', 'num_shares'])\n",
        "    ])\n",
        "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', classifier)\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Measure the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n"
      ],
      "metadata": {
        "id": "emgDVWo77IUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Function to fetch LinkedIn profile data\n",
        "def get_profile_data(url):\n",
        "    # Send a GET request to the LinkedIn profile URL\n",
        "    response = requests.get(url)\n",
        "    # Parse the HTML content\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    # Extract the summary section from the HTML content\n",
        "    summary = soup.find('div', {'class': 'pv-top-card-section__summary'}).get_text()\n",
        "    # Extract the experience section from the HTML content\n",
        "    experience = soup.find('section', {'class': 'pv-profile-section__section experience-section ember-view'}).get_text()\n",
        "    # Extract the education section from the HTML content\n",
        "    education = soup.find('section', {'class': 'pv-profile-section__section education-section ember-view'}).get_text()\n",
        "    # Extract the Job titles\n",
        "    job_titles = soup.find_all('h3', {'class': 't-16 t-black t-normal'})\n",
        "    job_titles = [title.get_text() for title in job_titles]\n",
        "    # Extract the number of connections\n",
        "    connections = soup.find('a', {'data-link-to': 'about:connections'}).get_text()\n",
        "    connections = int(connections.split(' ')[0])\n",
        "    # Extract the number of Recommendations\n",
        "    recommendations = soup.find('a', {'data-link-to': 'about:recommendations'}).get_text()\n",
        "    recommendations\n"
      ],
      "metadata": {
        "id": "pdF4Bc7o7WFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def get_big_five_scores(url):\n",
        "    \"\"\"\n",
        "    Function to fetch big five scores from a website\n",
        "    \"\"\"\n",
        "    # Fetch scores using API or webscrapping\n",
        "    scores = {\"Openness\":0.5, \"Conscientiousness\":0.6, \"Extraversion\":0.7, \"Agreeableness\":0.8, \"Neuroticism\":0.4 }\n",
        "    return scores\n",
        "\n",
        "def get_profile_data(url):\n",
        "    \"\"\"\n",
        "    Function to fetch LinkedIn profile data\n",
        "    \"\"\"\n",
        "    # Send a GET request to the LinkedIn profile URL\n",
        "    response = requests.get(url)\n",
        "    # Parse the HTML content\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    # Extract the summary section from the HTML content\n",
        "    summary = soup.find('div', {'class': 'pv-top-card-section__summary'}).get_text()\n",
        "    # Extract the experience section from the HTML content\n",
        "    experience = soup.find('section', {'class': 'pv-profile-section__section experience-section ember-view'}).get_text()\n",
        "    # Extract the education section from the HTML content\n",
        "    education = soup.find('section', {'class': 'pv-profile-section__section education-section ember-view'}).get_text()\n",
        "    # Extract the Job titles\n",
        "    job_titles = soup.find_all('h3', {'class': 't-16 t-black t-normal'})\n",
        "    job_titles = [title.get_text() for title in job_titles]\n",
        "    # Extract the number of connections\n",
        "    connections = soup.find('a', {'data-link-to': 'about:connections'}).get_text()\n",
        "    connections = int(connections.split(' ')[0])\n",
        "    # Extract the number of Recommendations\n",
        "    recommendations = soup.find('a', {'data-link-to': 'about:recommendations'}).get_text()\n",
        "    recommendations = int(recommendations.split(' ')[0])\n",
        "    # Extract the number of Posts and Shares made by the user\n",
        "    posts = soup.find_all('span', {'class': 'visually-hidden'})\n",
        "    num_posts = 0\n",
        "    num_shares = 0\n",
        "    for post in posts:\n",
        "        if 'post' in post.get_text():\n",
        "            num_posts += int(post.get_text().split(' ')[0])\n",
        "        elif 'share' in post.get_text():\n",
        "            num_shares += int(post.get_text().split(' ')[0])\n",
        "    # Combine the summary, experience, and education sections into a single string\n",
        "    profile\n"
      ],
      "metadata": {
        "id": "noxZugrg7aWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def get_big_five_scores(url):\n",
        "    \"\"\"\n",
        "    Function to fetch big five scores from a website\n",
        "    \"\"\"\n",
        "    # Fetch scores using API or webscrapping\n",
        "    scores = {\"Openness\":0.5, \"Conscientiousness\":0.6, \"Extraversion\":0.7, \"Agreeableness\":0.8, \"Neuroticism\":0.4 }\n",
        "    return scores\n",
        "\n",
        "def get_profile_data(url):\n",
        "    \"\"\"\n",
        "    Function to fetch LinkedIn profile data\n",
        "    \"\"\"\n",
        "    # Send a GET request to the LinkedIn profile URL\n",
        "    response = requests.get(url)\n",
        "    # Parse the HTML content\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    # Extract the summary section from the HTML content\n",
        "    summary = soup.find('div', {'class': 'pv-top-card-section__summary'}).get_text()\n",
        "    # Extract the experience section from the HTML content\n",
        "    experience = soup.find('section', {'class': 'pv-profile-section__section experience-section ember-view'}).get_text()\n",
        "    # Extract the education section from the HTML content\n",
        "    education = soup.find('section', {'class': 'pv-profile-section__section education-section ember-view'}).get_text()\n",
        "    # Extract the Job titles\n",
        "    job_titles = soup.find_all('h3', {'class': 't-16 t-black t-normal'})\n",
        "    job_titles = [\n"
      ],
      "metadata": {
        "id": "QW1CyJbL7dXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def get_big_five_scores(url):\n",
        "    \"\"\"\n",
        "    Function to fetch big five scores from a website\n",
        "    \"\"\"\n",
        "    # Fetch scores using API or webscrapping\n",
        "    scores = {\"Openness\":0.5, \"Conscientiousness\":0.6, \"Extraversion\":0.7, \"Agreeableness\":0.8, \"Neuroticism\":0.4 }\n",
        "    return scores\n",
        "\n",
        "def get_tone(summary, experience, education):\n",
        "    \"\"\"\n",
        "    Function to classify tone of text\n",
        "    \"\"\"\n",
        "    all_text = summary + experience + education\n",
        "    # Creating SentimentIntensityAnalyzer object\n",
        "    sid_obj = SentimentIntensityAnalyzer()\n",
        "    # Getting the polarity score\n",
        "    pol_score = sid_obj.polarity_scores(all_text)\n",
        "    if pol_score['compound'] >= 0.05:\n",
        "        tone = \"positive\"\n",
        "    elif pol_score['compound'] <= - 0.05:\n",
        "        tone = \"negative\"\n",
        "    else:\n",
        "        tone = \"neutral\"\n",
        "    return tone\n",
        "\n",
        "def get_profile_data(url):\n",
        "    \"\"\"\n",
        "    Function to fetch LinkedIn profile data\n",
        "    \"\"\"\n",
        "    # Send a GET request to the LinkedIn profile URL\n",
        "    response = requests.get(url)\n",
        "    # Parse the HTML content\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    # Extract the summary section from the HTML content\n",
        "    summary = soup.find('div', {'class': 'pv-top-card-section__summary'}).get_text()\n",
        "    # Extract the experience section from the HTML content\n",
        "    experience = soup.find('section', {'class': 'pv-profile-section__section experience-section ember-view'}).get_text()\n",
        "    # Extract the education section from the HTML content\n",
        "    education = soup.find('section', {'class': 'pv-profile-section__section education-section ember-view'}).get_text()\n",
        "    # Extract the Job titles\n",
        "    job_titles = soup.find_all('h3', {'class': 't-16 t-black t-normal'})\n",
        "    job_titles = [title.get_text() for title in job_titles]\n",
        "    # Extract the number of connections\n",
        "    connections = soup.find\n"
      ],
      "metadata": {
        "id": "DZ6pci_h7f-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def get_most_common_words(text, n=10):\n",
        "    \"\"\"\n",
        "    Function to get the most common words used in a text\n",
        "    \"\"\"\n",
        "    # Tokenize the text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # Convert the tokens to lowercase\n",
        "    tokens = [token.lower() for token in tokens]\n",
        "    # Remove punctuation and stopwords\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
        "    # Count the frequency of each token\n",
        "    word_freq = Counter(tokens)\n",
        "    # Get the n most common words\n",
        "    most_common_words = word_freq.most_common(n)\n",
        "    return most_common_words\n",
        "\n",
        "def get_profile_data(url):\n",
        "    \"\"\"\n",
        "    Function to fetch LinkedIn profile data\n",
        "    \"\"\"\n",
        "    # Send a GET request to the LinkedIn profile URL\n",
        "    response = requests.get(url)\n",
        "    # Parse the HTML content\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    # Extract the summary section from the HTML content\n",
        "    summary = soup.find('div', {'class': 'pv-top-card-section__summary'}).get_text()\n",
        "    # Extract the experience section from the HTML content\n",
        "    experience = soup.find('section', {'class': 'pv-profile-section__section experience-section ember-view'\n"
      ],
      "metadata": {
        "id": "efkRs7217jmu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}